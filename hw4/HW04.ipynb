{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 4 - CS348 Spring 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Description** - In this assignment, you will run and analyze binary classification using K-nearest neighbors and multiclass classification using a fully connected neural network.\n",
    "\n",
    "**Getting Started** - You should complete the assignment using your own installation of Python 3 and the packages numpy, pandas, keras, matplotlib, and seaborn. Download the assignment from Moodle and unzip the file. This will create a directory with this file, 'HW04.ipynb'.\n",
    "\n",
    "**Deliverables** - The assignment has a single deliverable: this jupyter notebook file saved as a pdf. Please answer all coding and writing questions in the body of this file. Once all of the answers are complete, download the file by navigating the following menus: File -> Download as -> PDF via LaTeX. Submit the downloaded pdf file on gradescope. Alternatively, you can save the file as a pdf via the following: File -> Print Preview -> Print as pdf.\n",
    "\n",
    "**Data Sets** - In this assignment, you will two datasets from the sci-kit learn repository, one on breast cancer and one on handwritten digits.\n",
    "\n",
    "**Academic Honesty Statement** - Copying solutions from external sources (books, web pages, etc.) or other students is considered cheating. Sharing your solutions with other students is considered cheating. Posting your code to public repositories such as GitHub is also considered cheating. Any detected cheating will result in a grade of 0 on the assignment for all students involved, and potentially a grade of F in the course. \n",
    "\n",
    "This academic honesty statement does not restrict you from reading official documentation or using other web resources for understanding the syntax of python, related data science libraries, or properties of distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# Do not import any other libraries other than those listed here. \n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn as skl\n",
    "import seaborn as sns\n",
    "import keras\n",
    "\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.datasets import load_breast_cancer, load_digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - KNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you'll use a K-nearest neighbors model to classify whether a tumor is benign or malignant in a breast cancer dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loading data.\n",
    "data = load_breast_cancer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = data['data'].shape[0]\n",
    "\n",
    "index = [346, 446, 385,  90, 353, 333, 408, 398, 151,  11, 326, 164, 244,\n",
    "       252, 471, 208,  30, 135,  12, 472, 109, 263,  62, 504, 313, 266,\n",
    "       301, 558, 460, 213, 498, 526, 444,  10, 264, 239,  44, 561, 543,\n",
    "        83,  87,  32, 551, 516, 358, 218, 552, 507, 272, 141, 533,  98,\n",
    "       190, 337, 243, 149,  13, 319, 285, 513, 383, 167, 295, 506, 563,\n",
    "       303, 162, 507, 451, 264, 270, 332, 566, 385, 334, 562, 191, 241,\n",
    "       133, 268, 453, 126, 175,  19, 114, 406, 281, 310, 323,  48, 218,\n",
    "       401, 541, 510, 114, 533,  54, 374, 127, 321, 487,  89, 300, 178,\n",
    "       356,  89, 430, 333,  37, 471, 486, 301, 183, 107, 164,  31,  77,\n",
    "       163, 568, 359, 443, 508, 274, 324,  67, 147,  83, 332, 470,  98,\n",
    "        90, 468,  95, 477, 403, 164, 189, 489, 199, 432, 212,  90,  94,\n",
    "        86, 184, 319, 448, 382, 296, 323, 551, 363, 386, 273, 407, 254,\n",
    "        97, 274, 459, 560, 154, 515, 559, 281,  79, 134, 451,   9, 252,\n",
    "       485, 305, 245, 221, 219, 467,  37, 497, 186, 327, 311, 236, 397,\n",
    "       189, 468, 334, 158, 231, 100, 542,  40, 410, 481, 359, 304, 269,\n",
    "       267, 194, 144,  48,  22, 381, 288, 507, 530, 393, 207,  47, 551,\n",
    "       202, 387, 239,  16, 286, 280, 553,  80, 327,  66, 452, 508, 446,\n",
    "       418, 280, 426, 468, 233, 284,  51, 117,  40, 502, 410, 109,  81,\n",
    "       449, 420,  10, 112,  25, 484, 315, 424,  70,  86, 229, 518, 567,\n",
    "       131, 454, 422, 251, 108,  95, 154, 215, 325, 341, 414, 502, 324,\n",
    "       364,  54,  82,   1, 177, 442, 144,  86, 337, 538, 453,   0, 251,\n",
    "       481,  58, 451, 537, 364, 479,  44, 207, 382, 194, 487, 562,   3,\n",
    "       460, 128, 278, 121, 431, 466, 361, 411, 556, 408, 370, 216, 443,\n",
    "       124, 408,   9, 316, 267, 380,  29, 549, 481, 137, 439, 328, 381,\n",
    "       112, 239, 141, 227, 337, 568, 173, 252, 456, 450, 257, 173, 182,\n",
    "       241, 328, 489,  14, 318, 166, 191, 235,   6,   8,  43, 508, 318,\n",
    "       465,  68, 488, 156, 238,  30, 484,  52, 249, 107, 259,  29, 359,\n",
    "       567, 521, 346, 429, 361, 123,  64, 180, 241, 219, 196,  67, 230,\n",
    "       483, 341, 410, 129,  94, 320, 172, 446, 125, 113, 451, 214, 273,\n",
    "        87, 198, 217, 284, 565, 172, 328,  57, 251, 513, 463,  43, 334,\n",
    "        91, 265, 547, 195, 434, 280, 371, 254, 351, 167, 190, 281, 259,\n",
    "       212, 323, 206, 168,  33, 565, 234, 147, 277,  56, 262, 290, 233,\n",
    "       178, 153, 423, 134,  84, 146, 358,  85, 112,  27, 563, 447, 197,\n",
    "       388,  37, 294, 106,  86, 253, 192, 175, 344, 556, 553, 375,   3,\n",
    "       495,  21,  73, 329, 435, 316, 463, 165, 287, 319, 429, 170, 343,\n",
    "       379, 546, 209, 524,   8, 538, 483, 131, 284, 338, 460,  89, 370,\n",
    "        62, 214, 429,  26, 133,  22,  13, 358, 390, 315,  24, 288, 191,\n",
    "       307, 494, 459, 375, 248,  43, 461, 304, 414,  73, 277,  15, 442,\n",
    "       261, 353, 465, 271, 542, 152, 431, 538, 305, 345, 132, 440, 111,\n",
    "       520, 524, 366,  83, 379, 446, 472,  88,  11, 113, 366, 431, 160,\n",
    "       435, 430, 519, 207, 290, 372, 513, 108, 327, 122, 395, 183, 414,\n",
    "       269, 326, 329, 169, 384,   5, 522, 161, 213, 197, 532, 451, 446,\n",
    "       358,  53, 373, 321, 422, 408, 441, 422, 338, 489,  10, 521, 150,\n",
    "       288, 545, 341,  25, 510, 330, 365,  45, 335,  89]\n",
    "\n",
    "x = data['data'][index]\n",
    "y = data['target'][index]\n",
    "\n",
    "x_train = x[:int(n/2)]#(x[:int(n/2)] - x.min(axis=0))/x.sum(axis=0)\n",
    "y_train = y[:int(n/2)]\n",
    "x_val = x[int(n/2):]#(x[int(n/2):] - x.min(axis=0))/x.sum(axis=0)\n",
    "y_val = y[int(n/2):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([1.206e+01, 1.890e+01, 7.666e+01, 4.453e+02, 8.386e-02, 5.794e-02,\n",
       "       7.510e-03, 8.488e-03, 1.555e-01, 6.048e-02, 2.430e-01, 1.152e+00,\n",
       "       1.559e+00, 1.802e+01, 7.180e-03, 1.096e-02, 5.832e-03, 5.495e-03,\n",
       "       1.982e-02, 2.754e-03, 1.364e+01, 2.706e+01, 8.654e+01, 5.626e+02,\n",
       "       1.289e-01, 1.352e-01, 4.506e-02, 5.093e-02, 2.880e-01, 8.083e-02])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 (15 points)  \n",
    "Using sci-kit learn's `KNeighborsClassifier` class, fit a K-nearest neighbors classifier between features `x_train` and targets `y_train`. Without using `KNeighborsClassifier`'s `score()` method or `sklearn.metrics.accuracy_score`, compute the classification accuracy of the model on the training data, `x_train` and `y_train`, as well as the validation data, `x_val` and `y_val`.\n",
    "\n",
    "Note: The classification accuracy is defined as N_correct / N, where N_correct is the number of correctly classified instances and N is the total number of instances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Part 1 Solution\n",
    "\n",
    "# --- write code here ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (20 points)  \n",
    "For every value of k between 1 and 50, fit a K-nearest neighbors classifier between features `x_train` and targets `y_train`. For each model, compute the classification accuracy of the model on the training data, `x_train` and `y_train`, as well as the validation data, `x_val` and `y_val`. Make a scatterplot with values of k on the horizontal axis and the classification accuracy on the vertical axis, using colors to distinguish between the evaluations on training and validation data.\n",
    "\n",
    "Describe how and why classification accuracy differs between the two datasets when k=1. Which value of k should we choose? Justify your answer in 2-3 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 Solution\n",
    "\n",
    "# --- write code here ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Written Response\n",
    "\n",
    "_Type your written response here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 (15 points)  \n",
    "Consider two new hypothetical datasets, `x_train_inf` and `x_val_inf` and their corresponding labels `y_train_inf` and `y_val_inf`, each of which contain an infinite number of samples from the same data generating process as parts 1-3. Disregarding computational and storage constraints, would you expect a K-nearest neighbors model trained on the `x_train_inf` and `y_train_inf` to achieve a classification accuracy of 1.0 when evaluated on `x_val_inf` and `y_val_inf`? Justify your answer in 2-3 sentences."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 Written Response\n",
    "\n",
    "_Type your written response here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 4 (5 points - Extra Credit)\n",
    "\n",
    "Your colleague claims that K-nearest neighbors is an inappropriate model for the raw data, and that the classifier could be improved by scaling each column of `x_train` to be between 0 and 1. Using your colleague's suggestion, train a new model and reproduce the plot from part 2. Explain how and why this data transformation changes the accuracy of the model.\n",
    "\n",
    "Hint: Whatever transformation you apply to `x_train` should also be applied to `x_val` when evaluating the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 4 Solution\n",
    "# --- write code here ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 4 Written Response\n",
    "\n",
    "_Type your written response here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you'll use a fully-connected neural network to classify a dataset of handwritten digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "digit_data = load_digits()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = digit_data['data'].shape[0]\n",
    "\n",
    "x = digit_data['data']\n",
    "y = digit_data['target']\n",
    "\n",
    "x_train = x[:int(n/2)]\n",
    "y_train = [keras.utils.to_categorical(y[:int(n/2)], num_classes=10)]\n",
    "x_val = x[int(n/2):]\n",
    "y_val = [keras.utils.to_categorical(y[int(n/2):], num_classes=10)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 1 (30 points)  \n",
    "Write a function `NN_model(n)`, which returns a compiled keras neural network model with n fully connected layers, each with 64 nodes and a rectified linear unit activation function. After each fully connected layer add a dropout layer with a dropout parameter of 0.1. After the n layers, add a final fully connected layer with 10 nodes and a sigmoid activation. Compile your model with a categorical crossentropy loss, the adam optimization method, and classification accuracy as the only metric.\n",
    "\n",
    "Hint: You may find it helpful to use the Keras sequential model API. https://keras.io/getting-started/sequential-model-guide/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 Solution\n",
    "# --- write code here ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 (20 points)  \n",
    "Train your neural network model on `x_train` and `y_train` with `n=1` for 50 epochs, a batch size of 100,  and `verbose=True`. Then evaluate your trained model on `x_val` and `y_val`. Is the classification accuracy monotonic increasing with the number of training steps? Explain why this relationship is/isn't monotonic in 2-3 sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 2 Solution\n",
    "# --- write code here ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 2 Written Response\n",
    "\n",
    "_Type your written response here_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 3 (5 points - Extra Credit)  \n",
    "For every integer value of n between 1 and 10, train a fully connected neural network using `NN_model(n)` on `x_train` and `y_train` and evaluate the trained model on `x_val` and `y_val`. Create a plot identical to the plot in Problem 1 part 2, except with n on the horizontal axis instead of k. Is this enough evidence to select a specific value for n? If not, what additional analysis would you suggest?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 3 Solution\n",
    "# --- write code here ---\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 3 Written Response\n",
    "\n",
    "_Type your written response here_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
