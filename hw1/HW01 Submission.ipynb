{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Homework 1 - CS348 Spring 2019"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Description ** - This assignment is intended to teach you about data processing using python, reporting descriptive statistics on a variety of data types, and thinking critically about common data processing challenges."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Getting Started** - You should complete the assignment using your own installation of Python 3 and the packages numpy and pandas. Download the assignment from Moodle and unzip the file. This will create a directory with this file, 'HW01.ipynb', and a 'data' directory. The data files for each data set are in the 'data' directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Deliverables ** - The assignment has two deliverables: a report and a jupyter notebook code file. You will submit both of these files together in a single compressed folder on Moodle.\n",
    "\n",
    "- ** Report ** -  The solution report will give your answers to the homework questions (listed below). You can use any software to create your report, but your report _must_ be submitted as a .pdf file.\n",
    "- ** Code ** - In order to submit the coding component of this assignment, first complete every coding assignment in this document by writing code in the sections labeled  --- write code here ---. After completing the coding problems save a copy of this file and submit it along with your report. This code should be written in a clean and organized fashion, and should be able to be run by the instructor and the TA by executing each code cell in order from top to bottom. It is strongly suggested that you reset the notebook and execute every cell in order before submitting."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Data Sets** - In this assignment, you will conduct a descriptive statistical analysis on 5 data files in the 'data' folder. The first dataset, 'census.csv', contains annonymized US census records. The remaining datasets contain samples from common univariate distributions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Academic Honesty Statement** â€” Copying solutions from external sources (books,\n",
    "web pages, etc.) or other students is considered cheating. Sharing your solutions with\n",
    "other students is considered cheating. Posting your code to public repositories such as\n",
    "GitHub is also considered cheating. Any detected cheating will result in a grade of 0 on\n",
    "the assignment for all students involved, and potentially a grade of F in the course.\n",
    "\n",
    "This academic honesty statement does not restrict you from reading official documentation or using other web resources for understanding the syntax of python, related data science libraries, or properties of distributions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Do not import any other libraries other than those listed here. \n",
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 1 - US Census Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you'll analyze a sample of publically released US Census data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1** (3 points)  \n",
    "Load the census.csv file into a pandas dataframe object. Once loaded, print the first 5 rows of the dataframe. See https://pandas.pydata.org/pandas-docs/version/0.21/generated/pandas.DataFrame.html for documentation on pandas dataframes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 Solution\n",
    "\n",
    "# --- write code here ---\n",
    "d = pd.read_csv(\"data/census.csv\")\n",
    "d = pd.DataFrame(data=d)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 2** (11 points)  \n",
    "For each variable (column), describe its statistical type from the following list:  \n",
    "\n",
    "- Nominal\n",
    "- Ordinal  \n",
    "- Interval \n",
    "- Ratio scale\n",
    "\n",
    "Justify your decision in a single sentence for each variable."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 3** (11 points)\n",
    "How might pandas datatypes such as int, float, string, etc. help determine a variable's statistical type? Are there any circumstances where using pandas datatypes would be misleading?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 4** (24 points)  \n",
    "Add a new column to the dataframe, 'College-Degree'. For each person in the census, assign a value of 1 to this column if they have completed an Associates, Bachelors, Masters, or Doctorate degree and a value of 0 otherwise. \n",
    "\n",
    "Is the average income for a person with a college degree greater than the average income for a person without a college degree? Is it possible to answer this question given the available data? If not, propose a variant of the question that can be answered and answer it.\n",
    "\n",
    "Hint: You may find it helpful to convert the 'Annual Income' column into numeric values. String matching in pandas is case sensitive, and can easily result in errors due to unanticipated string characters such as hyphens, underscores, and spaces."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "True\n"
     ]
    }
   ],
   "source": [
    "# Part 4 Solution\n",
    "\n",
    "# --- write code here ---\n",
    "conditions=[\n",
    "    d['Education'].str.strip()=='Associates',\n",
    "    d['Education'].str.strip()=='Bachelors',\n",
    "    d['Education'].str.strip()=='Masters',\n",
    "    d['Education'].str.strip()=='Doctorate'\n",
    "]\n",
    "choices=[1,1,1,1]\n",
    "d['College-Degree']=np.select(conditions,choices,0)\n",
    "\n",
    "d['Annual Income'].loc[d['Annual Income'].str.strip()=='<=50K']=49000\n",
    "d['Annual Income'].loc[d['Annual Income'].str.strip()=='>50K']=51000\n",
    "\n",
    "cincome=0\n",
    "ccount=0\n",
    "nincome=0\n",
    "ncount=0\n",
    "for index, row in d.iterrows():\n",
    "    if row['College-Degree']==1:\n",
    "        cincome += row['Annual Income']\n",
    "        ccount += 1\n",
    "    else:\n",
    "        nincome += row['Annual Income']\n",
    "        ncount += 1\n",
    "\n",
    "c_avg=cincome/ccount\n",
    "n_avg=nincome/ncount\n",
    "print(c_avg>n_avg)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "** Part 5** (24 points)    \n",
    "Like many real-world datasets, the census dataset contains several missing records. For this assignment we'll focus on missing records for the 'Occupation' and 'Country-of-Origin' variables.\n",
    "\n",
    "Construct a new dataframe which is a copy of the census dataframe, removing any rows where the 'Occupation' variable is missing. Compare the average 'Capital-Gain' and 'Capital-Loss' between the original and the filtered data frames. Repeat this procedure, instead removing any rows where the 'Country-of-Origin' variable is missing.\n",
    "\n",
    "How do our estimates of average 'Capital-Gain' and 'Capital-Loss' change when we omit the rows with missing 'Occupation' and 'Country-of-Origin' variables? Provide a plausible explanation for why filtering using different variables produces different results. Is this approach to handling missing data justified? Why or why not? If not, describe an alternative procedure for handling missing data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average origin gain: 1077.6488437087312\n",
      "Average origin loss: 87.303829734959\n",
      "Average rm occupation gain: 1106.0370792369295\n",
      "Average rm occupation loss: 88.91021550882219\n",
      "Average rm country gain: 1064.3606229282632\n",
      "Average rm country loss: 86.73935205453749\n"
     ]
    }
   ],
   "source": [
    "# Part 5 Solution\n",
    "\n",
    "# --- write code here ---\n",
    "d=pd.read_csv(\"data/census.csv\", sep=',', na_values=[' ?'], engine='python')\n",
    "rm_occ_copy=d.copy()\n",
    "rm_cou_copy=d.copy()\n",
    "\n",
    "rm_occ_copy=rm_occ_copy[pd.notnull(rm_occ_copy['Occupation'])]\n",
    "rm_cou_copy=rm_cou_copy[pd.notnull(rm_cou_copy['Country-of-Origin'])]\n",
    "\n",
    "origin_gain=0\n",
    "origin_loss=0\n",
    "origin_count=0\n",
    "\n",
    "copy1_gain=0\n",
    "copy1_loss=0\n",
    "copy1_count=0\n",
    "\n",
    "copy2_gain=0\n",
    "copy2_loss=0\n",
    "copy2_count=0\n",
    "\n",
    "for index, row in d.iterrows():\n",
    "    origin_gain += row['Capital-Gain']\n",
    "    origin_loss += row['Capital-Loss']\n",
    "    origin_count += 1\n",
    "\n",
    "for index, row in rm_occ_copy.iterrows():\n",
    "    copy1_gain += row['Capital-Gain']\n",
    "    copy1_loss += row['Capital-Loss']\n",
    "    copy1_count += 1\n",
    "        \n",
    "for index, row in rm_cou_copy.iterrows():\n",
    "    copy2_gain += row['Capital-Gain']\n",
    "    copy2_loss += row['Capital-Loss']\n",
    "    copy2_count += 1\n",
    "\n",
    "origin_avg_gain=origin_gain/origin_count\n",
    "origin_avg_loss=origin_loss/origin_count\n",
    "    \n",
    "rm_occ_avg_gain=copy1_gain/copy1_count\n",
    "rm_occ_avg_loss=copy1_loss/copy1_count\n",
    "\n",
    "rm_cou_avg_gain=copy2_gain/copy2_count\n",
    "rm_cou_avg_loss=copy2_loss/copy2_count\n",
    "\n",
    "print('Average origin gain: '+str(origin_avg_gain))\n",
    "print('Average origin loss: '+str(origin_avg_loss))\n",
    "print('Average rm occupation gain: '+str(rm_occ_avg_gain))\n",
    "print('Average rm occupation loss: '+str(rm_occ_avg_loss))\n",
    "print('Average rm country gain: '+str(rm_cou_avg_gain))\n",
    "print('Average rm country loss: '+str(rm_cou_avg_loss))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problem 2 - Synthetic Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this problem you'll be asked to compare samples from the following 4 distributions.\n",
    "\n",
    " - Poisson\n",
    " - Uniform\n",
    " - Normal\n",
    " - Truncated Normal\n",
    "\n",
    "These datasets of samples have been randomly orderred, and are named 'synthetic1.csv', 'synthetic2.csv', etc. in the 'data' directory."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 1** (3 points)    \n",
    "Load each of the 4 datasets as numpy arrays. See https://docs.scipy.org/doc/numpy/user/index.html for documentation on numpy arrays."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Part 1 Solution\n",
    "\n",
    "# --- write code here ---\n",
    "file1=np.genfromtxt(\"data/synthetic1.csv\",delimiter=',',dtype=None)\n",
    "file2=np.genfromtxt(\"data/synthetic2.csv\",delimiter=',',dtype=None)\n",
    "file3=np.genfromtxt(\"data/synthetic3.csv\",delimiter=',',dtype=None)\n",
    "file4=np.genfromtxt(\"data/synthetic4.csv\",delimiter=',',dtype=None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Part 2**  (24 points)    \n",
    "Match each dataset of samples to the distribution that was used to generate it **without using any visualization tools such as matplotlib**. Visualization is an important method in data science, but will be covered in future homeworks. \n",
    "\n",
    "Describe your findings in the report, including a 1-2 sentence justification for each dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(array([   14,   406,  3603, 15675, 31981, 30832, 14141,  3018,   310,\n",
      "          20]), array([-4.45563583, -3.55623941, -2.65684299, -1.75744657, -0.85805015,\n",
      "        0.04134627,  0.94074269,  1.84013911,  2.73953554,  3.63893196,\n",
      "        4.53832838]))\n",
      "(array([  671,  2636,  8004, 15964, 22511, 22739, 15899,  7942,  2718,\n",
      "         667]), array([-2.99441180e+00, -2.39511268e+00, -1.79581356e+00, -1.19651444e+00,\n",
      "       -5.97215319e-01,  2.08380241e-03,  6.01382923e-01,  1.20068204e+00,\n",
      "        1.79998117e+00,  2.39928029e+00,  2.99857941e+00]))\n",
      "(array([36532, 37087, 18394,  6115,     0,  1482,   323,    60,     6,\n",
      "           1]), array([0. , 0.8, 1.6, 2.4, 3.2, 4. , 4.8, 5.6, 6.4, 7.2, 8. ]))\n",
      "(array([ 9984,  9992,  9855, 10028,  9949, 10068, 10117, 10036, 10041,\n",
      "        9930]), array([-2.99995042e+00, -2.39996251e+00, -1.79997459e+00, -1.19998668e+00,\n",
      "       -5.99998772e-01, -1.08604697e-05,  5.99977051e-01,  1.19996496e+00,\n",
      "        1.79995287e+00,  2.39994078e+00,  2.99992870e+00]))\n"
     ]
    }
   ],
   "source": [
    "# Part 2 Solution\n",
    "\n",
    "# --- write code here ---\n",
    "hist1=np.histogram(file1)\n",
    "print(hist1)\n",
    "hist2=np.histogram(file2)\n",
    "print(hist2)\n",
    "hist3=np.histogram(file3)\n",
    "print(hist3)\n",
    "hist4=np.histogram(file4)\n",
    "print(hist4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
